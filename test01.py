"""
Spark è½»é‡æµ‹è¯• - ä¿®æ­£ç‰ˆ
è§£å†³æ•°æ®åº“å­—æ®µç¼ºå¤± (Field doesn't have a default value) é—®é¢˜
"""
import os
import traceback
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, avg, count, lit, desc, current_timestamp, when

print("=" * 70)
print("ğŸ§ª Spark è½»é‡æµ‹è¯• (Fix Version) - å¤„ç† 100 æ¡æ•°æ®")
print("=" * 70)

# ---------------------------------------------------------
# 1. é…ç½®éƒ¨åˆ†
# ---------------------------------------------------------
RDS_HOST = "recommendation-db.croqeqgd3egv.us-east-1.rds.amazonaws.com"
RDS_DB = "recommendation_db"
RDS_USER = "admin"
RDS_PASSWORD = "RecommendDB2026!"
JDBC_URL = f"jdbc:mysql://{RDS_HOST}:3306/{RDS_DB}?useSSL=false&allowPublicKeyRetrieval=true"

print(f"\næ•°æ®åº“: {RDS_HOST}/{RDS_DB}")

# åˆ›å»º Spark Session
print("\nğŸ“¦ åˆ›å»º Spark Session (limited resources)...")
spark = SparkSession.builder \
    .appName("MovieLens-Mini-Test-Fix") \
    .master("local[1]") \
    .config("spark.driver.memory", "512m") \
    .config("spark.executor.memory", "512m") \
    .config("spark.sql.shuffle.partitions", "2") \
    # ç¡®ä¿åŒ…å« mysql é©±åŠ¨
    .config("spark.jars.packages", "mysql:mysql-connector-java:8.0.33") \
    .getOrCreate()

spark.sparkContext.setLogLevel("ERROR")
print("âœ… Spark Session åˆ›å»ºæˆåŠŸ")

try:
    # ---------------------------------------------------------
    # 2. è¯»å–æ•°æ® & è®¡ç®—
    # ---------------------------------------------------------
    
    # è¯»å– Movies (å‰100æ¡)
    print("\nğŸ“‚ è¯»å– movies.csv (å‰100æ¡)...")
    movies_full = spark.read.csv("data/movies.csv", header=True, inferSchema=True)
    movies_df = movies_full.limit(100)
    
    # è·å–è¿™äº›ç”µå½±çš„ ID ç”¨äºè¿‡æ»¤è¯„åˆ†
    movie_ids = [row.movieId for row in movies_df.select("movieId").collect()]
    print(f"   å·²åŠ è½½ {len(movie_ids)} éƒ¨ç”µå½±")

    # è¯»å– Ratings
    print(f"\nğŸ“‚ è¯»å– ratings.csv (å…³è”è¯„åˆ†)...")
    ratings_full = spark.read.csv("data/ratings.csv", header=True, inferSchema=True)
    ratings_df = ratings_full.filter(col("movieId").isin(movie_ids))
    print(f"   å·²åŠ è½½ {ratings_df.count()} æ¡è¯„åˆ†")

    # è®¡ç®—ç»Ÿè®¡æ•°æ® (Avg, Count)
    print(f"\nğŸ”¢ è®¡ç®—æ¨èåˆ†æ•°...")
    movie_stats = ratings_df.groupBy("movieId").agg(
        avg("rating").alias("avg_rating"),
        count("rating").alias("rating_count")
    )

    # è´å¶æ–¯åŠ æƒè®¡ç®—
    avg_rating_all = ratings_df.agg(avg("rating")).first()[0] or 3.0 # é˜²æ­¢ä¸ºç©ºç»™ä¸ªé»˜è®¤å€¼
    m = 10
    C = avg_rating_all

    # ç”Ÿæˆæ¨èåˆ†æ•°è¡¨
    recommendations = movie_stats.withColumn(
        "recommendation_score",
        ((col("rating_count") / (col("rating_count") + lit(m))) * col("avg_rating") +
         (lit(m) / (col("rating_count") + lit(m))) * lit(C))
    )

    # ---------------------------------------------------------
    # 3. å‡†å¤‡å†™å…¥ Movies è¡¨ (å…³é”®ä¿®æ”¹)
    # ---------------------------------------------------------
    print(f"\nğŸ’¾ æ­£åœ¨å†™å…¥æ•°æ®åº“...")

    # A. å‡†å¤‡ Movies æ•°æ®ï¼šéœ€è¦åˆå¹¶ç»Ÿè®¡ä¿¡æ¯ï¼Œå¹¶è¡¥å…¨æ•°æ®åº“å¿…å¡«å­—æ®µ
    print(f"   [1/2] å†™å…¥ movies è¡¨...")
    
    # å…³è” movies_df å’Œ movie_statsï¼Œå¦‚æœæ²¡æœ‰è¯„åˆ†ï¼Œå¡«å……é»˜è®¤å€¼
    movies_ready = movies_df.join(movie_stats, "movieId", "left") \
        .na.fill({"avg_rating": 0.0, "rating_count": 0})

    # æ„é€ ç¬¦åˆæ•°æ®åº“ schema çš„ DataFrame
    movies_to_db = movies_ready.select(
        col("movieId").alias("movie_id"),      # å¯¹åº”æ•°æ®åº“ movie_id
        col("title"),                          # å¯¹åº”æ•°æ®åº“ title
        col("genres"),                         # å¯¹åº”æ•°æ®åº“ genres
        col("avg_rating"),                     # âœ… è¡¥å…¨: æ•°æ®åº“å¿…å¡«
        col("rating_count")                    # âœ… è¡¥å…¨: æ•°æ®åº“å¿…å¡«
    ).withColumn("year", lit(None).cast("int")) \
     .withColumn("created_at", current_timestamp()) \
     .withColumn("updated_at", current_timestamp())

    # å†™å…¥ movies
    movies_to_db.write.format("jdbc") \
        .option("url", JDBC_URL) \
        .option("dbtable", "movies") \
        .option("user", RDS_USER) \
        .option("password", RDS_PASSWORD) \
        .option("driver", "com.mysql.cj.jdbc.Driver") \
        .mode("append") \
        .save()
    
    print(f"   âœ… movies è¡¨å†™å…¥æˆåŠŸ")

    # ---------------------------------------------------------
    # 4. å‡†å¤‡å†™å…¥ Recommendation Data è¡¨ (å…³é”®ä¿®æ”¹)
    # ---------------------------------------------------------
    print(f"   [2/2] å†™å…¥ recommendation_data è¡¨...")

    # B. å‡†å¤‡ Recommendation æ•°æ®ï¼šè¡¥å…¨ popularity, score, timestamps ç­‰
    # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ç›´æ¥ Join å‰é¢ç®—å¥½çš„ recommendations
    
    rec_to_db = recommendations.select(
        col("movieId").alias("movie_id"),        # å¯¹åº”æ•°æ®åº“ movie_id (æ³¨æ„å¤–é”®é€»è¾‘)
        col("recommendation_score")              # å¯¹åº”æ•°æ®åº“ recommendation_score
    ).withColumn("popularity_score", lit(0.0)) \
     .withColumn("genre_match_score", lit(0.0)) \
     .withColumn("user_id", lit(None).cast("int")) \
     .withColumn("created_at", current_timestamp()) \
     .withColumn("updated_at", current_timestamp())

    # å†™å…¥ recommendation_data
    rec_to_db.write.format("jdbc") \
        .option("url", JDBC_URL) \
        .option("dbtable", "recommendation_data") \
        .option("user", RDS_USER) \
        .option("password", RDS_PASSWORD) \
        .option("driver", "com.mysql.cj.jdbc.Driver") \
        .mode("append") \
        .save()

    print(f"   âœ… recommendation_data è¡¨å†™å…¥æˆåŠŸ")

    print("\n" + "=" * 70)
    print("ğŸ‰ğŸ‰ğŸ‰ æµ‹è¯•å®Œæˆï¼æ‰€æœ‰æ•°æ®å·²æˆåŠŸå†™å…¥ RDS")
    print("=" * 70)

except Exception as e:
    print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {type(e).__name__}")
    print(f"   è¯¦ç»†ä¿¡æ¯: {str(e)}")
    print("-" * 30)
    traceback.print_exc()

finally:
    if 'spark' in locals():
        spark.stop()
        print("\nğŸ›‘ Spark Session å·²åœæ­¢")